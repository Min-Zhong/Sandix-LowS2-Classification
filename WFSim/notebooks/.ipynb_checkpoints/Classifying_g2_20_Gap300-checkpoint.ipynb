{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Trained Model to do Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the BDT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmind/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import all the things needed for the BDT training\n",
    "import random\n",
    "import pandas\n",
    "import pandas.core.common as com\n",
    "from pandas.core.index import Index\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "# Load the BDT model\n",
    "bdt = joblib.load('../BDT_model_g2_20_Gap300/BDTmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating S1s and S2s seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating S1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmind/anaconda3/lib/python3.7/site-packages/datashader/transfer_functions.py:21: FutureWarning: xarray subclass Image should explicitly define __slots__\n",
      "  class Image(xr.DataArray):\n"
     ]
    }
   ],
   "source": [
    "# Just import something needed\n",
    "import numpy as np\n",
    "import strax\n",
    "import straxen\n",
    "import wfsim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from multihist import Histdd, Hist1d\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strax Settings\n",
    "n_photon_min = 50\n",
    "n_photon_max = 250\n",
    "n_electron_min = 1\n",
    "n_electron_max = 5\n",
    "\n",
    "st = strax.Context(\n",
    "    register=wfsim.RawRecordsFromFax,\n",
    "#     config=dict((detector=\"XENONnT\"))\n",
    "    **straxen.contexts.common_opts)\n",
    "\n",
    "st.set_config(dict(fax_file=None))\n",
    "st.set_config(dict(peak_gap_threshold=300))\n",
    "\n",
    "strax.Mailbox.DEFAULT_TIMEOUT=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating S1s\n",
    "st.set_config(dict(nchunk=1, event_rate = 1, chunk_size = 2000))\n",
    "\n",
    "run_id = '170503_0504'\n",
    "\n",
    "dtype = wfsim.strax_interface.instruction_dtype\n",
    "\n",
    "def rand_instructions(c):\n",
    "    n = c['nevents'] = c['event_rate'] * c['chunk_size'] * c['nchunk']\n",
    "    c['total_time'] = c['chunk_size'] * c['nchunk']\n",
    "\n",
    "    instructions = np.zeros(1 * n, dtype=dtype)\n",
    "    uniform_times = c['total_time'] * (np.arange(n) + 0.5) / n\n",
    "    instructions['t'] = np.repeat(uniform_times, 1) * int(1e9)\n",
    "    instructions['event_number'] = np.digitize(instructions['t'], \n",
    "         1e9 * np.arange(c['nchunk']) * c['chunk_size']) - 1\n",
    "    instructions['type'] = np.tile(['s1'], n)\n",
    "    instructions['recoil'] = ['er' for i in range(n * 1)]\n",
    "\n",
    "    r = np.sqrt(np.random.uniform(0, 2500, n))\n",
    "    t = np.random.uniform(-np.pi, np.pi, n)\n",
    "    instructions['x'] = np.repeat(r * np.cos(t), 1)\n",
    "    instructions['y'] = np.repeat(r * np.sin(t), 1)\n",
    "    instructions['z'] = np.repeat(np.random.uniform(-100, 0, n), 1)\n",
    "\n",
    "    nphotons = np.random.uniform(n_photon_min, n_photon_max, n)\n",
    "    nelectrons = np.random.uniform(n_electron_min, n_electron_max, n)\n",
    "    instructions['amp'] = np.vstack([nphotons]).T.flatten().astype(int)\n",
    "\n",
    "    return instructions\n",
    "\n",
    "wfsim.strax_interface.rand_instructions = rand_instructions\n",
    "wfsim.strax_interface.instruction_dtype = dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_s1 = st.get_array(run_id,'records')\n",
    "peaks_s1 = st.get_array(run_id, ['peaks','peak_classification'])\n",
    "truth_s1 = st.get_df(run_id, 'truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of signals classified as S1:  1991\n",
      "Number of signals classified as S2:  1\n",
      "Number of signals classified as neither S1 nor S2:  10\n",
      "All signals:  2002\n"
     ]
    }
   ],
   "source": [
    "print('Number of signals classified as S1: ', len(peaks_s1[peaks_s1['type']==1]['type']))\n",
    "print('Number of signals classified as S2: ', len(peaks_s1[peaks_s1['type']==2]['type']))\n",
    "print('Number of signals classified as neither S1 nor S2: ', len(peaks_s1[peaks_s1['type']==0]['type']))\n",
    "print('All signals: ',len(peaks_s1['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true S1 signals:  1994\n",
      "Number of correctly classified S1:  1987\n"
     ]
    }
   ],
   "source": [
    "peaks_true_s1 = peaks_s1[5e+8-peaks_s1['time']%(5e+8)<600]\n",
    "peaks_classified_true_s1 = peaks_s1[(5e+8-peaks_s1['time']%(5e+8)<600) & (peaks_s1['type']==1)]\n",
    "print('Number of true S1 signals: ', len(peaks_true_s1))\n",
    "print('Number of correctly classified S1: ', len(peaks_classified_true_s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating S2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating S2s\n",
    "st.set_config(dict(nchunk=1, event_rate = 1, chunk_size = 2000))\n",
    "\n",
    "run_id = '170504_0505'\n",
    "\n",
    "dtype = wfsim.strax_interface.instruction_dtype\n",
    "\n",
    "def rand_instructions(c):\n",
    "    n = c['nevents'] = c['event_rate'] * c['chunk_size'] * c['nchunk']\n",
    "    c['total_time'] = c['chunk_size'] * c['nchunk']\n",
    "\n",
    "    instructions = np.zeros(1 * n, dtype=dtype)\n",
    "    uniform_times = c['total_time'] * (np.arange(n) + 0.5) / n\n",
    "    instructions['t'] = np.repeat(uniform_times, 1) * int(1e9)\n",
    "    instructions['event_number'] = np.digitize(instructions['t'], \n",
    "         1e9 * np.arange(c['nchunk']) * c['chunk_size']) - 1\n",
    "    instructions['type'] = np.tile(['s2'], n)\n",
    "    instructions['recoil'] = ['er' for i in range(n * 1)]\n",
    "\n",
    "    r = np.sqrt(np.random.uniform(0, 2500, n))\n",
    "    t = np.random.uniform(-np.pi, np.pi, n)\n",
    "    instructions['x'] = np.repeat(r * np.cos(t), 1)\n",
    "    instructions['y'] = np.repeat(r * np.sin(t), 1)\n",
    "    instructions['z'] = np.repeat(np.random.uniform(-100, 0, n), 1)\n",
    "\n",
    "    nphotons = np.random.uniform(n_photon_min, n_photon_max, n)\n",
    "    nelectrons = np.random.uniform(n_electron_min, n_electron_max, n)\n",
    "    instructions['amp'] = np.vstack([nelectrons]).T.flatten().astype(int)\n",
    "\n",
    "    return instructions\n",
    "\n",
    "wfsim.strax_interface.rand_instructions = rand_instructions\n",
    "wfsim.strax_interface.instruction_dtype = dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_s2 = st.get_array(run_id,'records')\n",
    "peaks_s2 = st.get_array(run_id, ['peaks','peak_classification'])\n",
    "truth_s2 = st.get_df(run_id, 'truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of signals classified as S1:  386\n",
      "Number of signals classified as S2:  1107\n",
      "All signals:  1981\n"
     ]
    }
   ],
   "source": [
    "print('Number of signals classified as S1: ', len(peaks_s2[peaks_s2['type']==1]['type']))\n",
    "print('Number of signals classified as S2: ', len(peaks_s2[peaks_s2['type']==2]['type']))\n",
    "print('All signals: ',len(peaks_s2['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Peak_classification Correct Rate\n",
    "dtype_temp = peaks_s2.dtype\n",
    "peaks_true_s2 = np.zeros(0, dtype=dtype_temp)\n",
    "peaks_afterpulse = np.zeros(0, dtype=dtype_temp)\n",
    "truth_s2_time = truth_s2[['t_first_photon']].values\n",
    "for ipeak in peaks_s2:\n",
    "    for time in truth_s2_time:\n",
    "        peaks_temp = np.zeros(0, dtype=dtype_temp)\n",
    "        if ((time[0]-ipeak['time'] > 0) & (time[0]-ipeak['time'] < 1000)):\n",
    "            peaks_true_s2 = np.append(peaks_true_s2, ipeak)    \n",
    "        elif ((time[0]-ipeak['time'] > -750000) & (time[0]-ipeak['time'] < 0)):\n",
    "            peaks_afterpulse = np.append(peaks_afterpulse, ipeak)\n",
    "            \n",
    "peaks_classified_s1 = peaks_s2[peaks_s2['type']==1].copy()\n",
    "peaks_classified_s2 = peaks_s2[peaks_s2['type']==2].copy() \n",
    "\n",
    "peaks_classified_true_s2 = np.zeros(0, dtype=dtype_temp)\n",
    "truth_s2_time = truth_s2[['t_first_photon']].values\n",
    "for ipeak in peaks_classified_s2:\n",
    "    for time in truth_s2_time:\n",
    "        if ((time[0]-ipeak['time'] > 0) & (time[0]-ipeak['time'] < 600)):\n",
    "            peaks_classified_true_s2 = np.append(peaks_classified_true_s2, ipeak)\n",
    "\n",
    "print('Number of true s2 signals (can be found based on truth time info): ', len(peaks_true_s2))\n",
    "print('Number of after pulses: ', len(peaks_afterpulse))\n",
    "print('Number of signals judged as S1: ', len(peaks_classified_s1))\n",
    "print('Number of signals judged as S2: ', len(peaks_classified_s2))\n",
    "print('Among them, number of true S2: ', len(peaks_classified_true_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truth_s2[(np.isnan(truth_s2.t_first_photon))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1 and S2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the Area Distribution\n",
    "fig=plt.figure(figsize=(8,5.5))\n",
    "fig.patch.set_color('white')\n",
    "plt.hist(peaks_true_s1['area'],bins=100,range=(0,50),color='goldenrod',histtype='step',label='True S1')\n",
    "plt.hist(peaks_true_s2['area'],bins=100,range=(0,50),color='r',histtype='step',label='True S2')\n",
    "plt.hist(peaks_classified_s2['area'],bins=100,range=(0,50),color='b',histtype='step',label='Classified as S2')\n",
    "plt.hist(peaks_classified_true_s2['area'],bins=100,range=(0,50),color='g',histtype='step',label='Correctly Classified S2')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('size [PE]')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Signal Size Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the arraies for classification\n",
    "peaks_true_s1_features_list = []\n",
    "peaks_true_s2_features_list = []\n",
    "peaks_afterpulse_features_list = []\n",
    "\n",
    "peaks_true_s1_area_list = []\n",
    "peaks_true_s2_area_list = []\n",
    "peaks_afterpulse_area_list = []\n",
    "\n",
    "for i in range(0, len(peaks_true_s1)):\n",
    "    peaks_true_s1_features_list.append([peaks_true_s1['width'][i,5], peaks_true_s1['width'][i,9],\n",
    "                                        peaks_true_s1['width'][i,5]/peaks_true_s1['width'][i,9], \n",
    "                                        -peaks_true_s1['area_decile_from_midpoint'][i,1], peaks_true_s1['area_decile_from_midpoint'][i,9],\n",
    "                                        -peaks_true_s1['area_decile_from_midpoint'][i,1]/peaks_true_s1['area_decile_from_midpoint'][i,9]])\n",
    "    peaks_true_s1_area_list.append([peaks_true_s1['area'][i]])\n",
    "\n",
    "for i in range(0, len(peaks_true_s2)):\n",
    "    peaks_true_s2_features_list.append([peaks_true_s2['width'][i,5], peaks_true_s2['width'][i,9],\n",
    "                                        peaks_true_s2['width'][i,5]/peaks_true_s2['width'][i,9],\n",
    "                                        -peaks_true_s2['area_decile_from_midpoint'][i,1], peaks_true_s2['area_decile_from_midpoint'][i,9],\n",
    "                                        -peaks_true_s2['area_decile_from_midpoint'][i,1]/peaks_true_s2['area_decile_from_midpoint'][i,9]])\n",
    "    peaks_true_s2_area_list.append([peaks_true_s2['area'][i]])\n",
    "\n",
    "for i in range(0, len(peaks_afterpulse)):\n",
    "    peaks_afterpulse_features_list.append([peaks_afterpulse['width'][i,5], peaks_afterpulse['width'][i,9], \n",
    "                                           peaks_afterpulse['width'][i,5]/peaks_afterpulse['width'][i,9],\n",
    "                                           -peaks_afterpulse['area_decile_from_midpoint'][i,1], peaks_afterpulse['area_decile_from_midpoint'][i,9], \n",
    "                                           -peaks_afterpulse['area_decile_from_midpoint'][i,1]/peaks_afterpulse['area_decile_from_midpoint'][i,9]])\n",
    "    peaks_afterpulse_area_list.append([peaks_afterpulse['area'][i]])\n",
    "    \n",
    "peaks_true_s1_features = np.asarray(peaks_true_s1_features_list)\n",
    "peaks_true_s2_features = np.asarray(peaks_true_s2_features_list)\n",
    "peaks_afterpulse_features = np.asarray(peaks_afterpulse_features_list)\n",
    "\n",
    "dtype_area = [('area', float)]\n",
    "peaks_true_s1_area = np.asarray(peaks_true_s1_area_list, dtype_area)\n",
    "peaks_true_s2_area = np.asarray(peaks_true_s2_area_list, dtype_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the BDT score distribution\n",
    "BDTscore_true_s1 = bdt.decision_function(peaks_true_s1_features)\n",
    "BDTscore_true_s2 = bdt.decision_function(peaks_true_s2_features)\n",
    "BDTscore_afterpulse = bdt.decision_function(peaks_afterpulse_features)\n",
    "\n",
    "BDT_lower_lim = 0.0\n",
    "\n",
    "fig=plt.figure(figsize=(8,5.5))\n",
    "fig.patch.set_color('white')\n",
    "plt.hist(BDTscore_true_s1,bins=100,range=(-0.5,1.1),color='r',histtype='step',label='True S1')\n",
    "plt.hist(BDTscore_true_s2,bins=100,range=(-0.5,1.1),color='g',histtype='step',label='True S2')\n",
    "plt.hist(BDTscore_afterpulse,bins=100,range=(-0.5,1.1),color='b',histtype='step',label='Afterpulses')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel('BDT score')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('BDT Score Distribution of Afterpulses')\n",
    "plt.vlines(BDT_lower_lim, 0, 98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BDTscore_true_s1[BDTscore_true_s1>BDT_lower_lim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Correct Judgement Rate\n",
    "print ('Among All True S1 Signals (', len(peaks_true_s1), 'Found ):          Peak Classification           BDT Classification  ')\n",
    "print ('Correctly Judged as S1                               ', \n",
    "       round(len(peaks_true_s1[peaks_true_s1['type']==1])/len(peaks_true_s1), 4),\n",
    "       '                        ',\n",
    "       round(len(BDTscore_true_s1[BDTscore_true_s1>BDT_lower_lim])/len(peaks_true_s1), 4))\n",
    "print ('Incorrectly Judged as S2                             ', \n",
    "       round(len(peaks_true_s1[peaks_true_s1['type']==2])/len(peaks_true_s1), 4),\n",
    "       '                           ',\n",
    "       round(len(BDTscore_true_s1[BDTscore_true_s1<BDT_lower_lim])/len(peaks_true_s1), 4))\n",
    "\n",
    "print ('')\n",
    "\n",
    "print ('Among All True S2 Signals (', len(peaks_true_s2), 'Found ):           Peak Classification           BDT Classification  ')\n",
    "print ('Correctly Judged as S2                               ', \n",
    "       round(len(peaks_true_s2[peaks_true_s2['type']==2])/len(peaks_true_s2), 4),\n",
    "       '                        ',\n",
    "       round(len(BDTscore_true_s2[BDTscore_true_s2<BDT_lower_lim])/len(peaks_true_s2), 4))\n",
    "print ('Incorrectly Judged as S1                             ', \n",
    "       round(len(peaks_true_s2[peaks_true_s2['type']==1])/len(peaks_true_s2), 4),\n",
    "       '                        ',\n",
    "       round(len(BDTscore_true_s2[BDTscore_true_s2>BDT_lower_lim])/len(peaks_true_s2), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the Correct Judgement Rate\n",
    "peaks_true_s1_area_BDT_list = []\n",
    "peaks_true_s2_area_BDT_list = []\n",
    "\n",
    "for i in range(0, len(BDTscore_true_s1)):\n",
    "    if BDTscore_true_s1[i] > BDT_lower_lim:\n",
    "        peaks_true_s1_area_BDT_list.append(peaks_true_s1_area[i])\n",
    "\n",
    "for i in range(0, len(BDTscore_true_s2)):\n",
    "    if BDTscore_true_s2[i] < BDT_lower_lim:\n",
    "        peaks_true_s2_area_BDT_list.append(peaks_true_s2_area[i])\n",
    "\n",
    "peaks_true_s1_area_BDT = np.asarray(peaks_true_s1_area_BDT_list, dtype_area)\n",
    "peaks_true_s2_area_BDT = np.asarray(peaks_true_s2_area_BDT_list, dtype_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bin = np.linspace(0,50,100)\n",
    "list_rate_raw = []\n",
    "list_rate_bdt = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    value_raw = len(peaks_classified_true_s1[(peaks_classified_true_s1['area'] > 0.5*i) & (peaks_classified_true_s1['area'] < 0.5*(i+1))])\n",
    "    value_bdt = len(peaks_true_s1_area_BDT[(peaks_true_s1_area_BDT['area'] > 0.5*i) & (peaks_true_s1_area_BDT['area'] < 0.5*(i+1))])\n",
    "    base = len(peaks_true_s1_area[(peaks_true_s1_area['area'] > 0.5*i) & (peaks_true_s1_area['area'] < 0.5*(i+1))])\n",
    "    if (base!=0):\n",
    "        rate_raw = value_raw/base\n",
    "        rate_bdt = value_bdt/base\n",
    "    elif (base==0):\n",
    "        if (value_raw==0):\n",
    "            rate_raw = 1\n",
    "        else: \n",
    "            rate_raw = 100\n",
    "            \n",
    "        if (value_bdt==0):\n",
    "            rate_bdt = 1\n",
    "        else:\n",
    "            rate_bdt = 100\n",
    "\n",
    "    list_rate_raw.append(rate_raw)\n",
    "    list_rate_bdt.append(rate_bdt)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.patch.set_color('white')\n",
    "plt.step(list_bin, list_rate_raw, color='r', alpha=0.8, label='Strax Classification')\n",
    "plt.step(list_bin, list_rate_bdt, color='b', alpha=0.8, label='BDT Classification' )\n",
    "plt.title('S1 Correct Classification Rate')\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0,1.2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('s1 [PE]')\n",
    "plt.ylabel('Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bin = np.linspace(0,50,100)\n",
    "list_rate_raw = []\n",
    "list_rate_bdt = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    value_raw = len(peaks_classified_true_s2[(peaks_classified_true_s2['area'] > 0.5*i) & (peaks_classified_true_s2['area'] < 0.5*(i+1))])\n",
    "    value_bdt = len(peaks_true_s2_area_BDT[(peaks_true_s2_area_BDT['area'] > 0.5*i) & (peaks_true_s2_area_BDT['area'] < 0.5*(i+1))])\n",
    "    base = len(peaks_true_s2_area[(peaks_true_s2_area['area'] > 0.5*i) & (peaks_true_s2_area['area'] < 0.5*(i+1))])\n",
    "    if (base!=0):\n",
    "        rate_raw = value_raw/base\n",
    "        rate_bdt = value_bdt/base\n",
    "    elif (base==0):\n",
    "        if (value_raw==0):\n",
    "            rate_raw = 1\n",
    "        else: \n",
    "            rate_raw = 100\n",
    "            \n",
    "        if (value_bdt==0):\n",
    "            rate_bdt = 1\n",
    "        else:\n",
    "            rate_bdt = 100\n",
    "\n",
    "    list_rate_raw.append(rate_raw)\n",
    "    list_rate_bdt.append(rate_bdt)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.patch.set_color('white')\n",
    "plt.step(list_bin, list_rate_raw, color='r', alpha=0.8, label='Strax Classification')\n",
    "plt.step(list_bin, list_rate_bdt, color='b', alpha=0.8, label='BDT Classification' )\n",
    "plt.title('S2 Correct Classification Rate')\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0,1.2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('s2 [PE]')\n",
    "plt.ylabel('Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Cut\n",
    "print ('S1 correct classification rate (simple cut): ', len(peaks_true_s1[-peaks_true_s1['area_decile_from_midpoint'][:,1]<60]) / len(peaks_true_s1))\n",
    "print ('S2 correct classification rate (simple cut): ', len(peaks_true_s2[-peaks_true_s2['area_decile_from_midpoint'][:,1]>60]) / len(peaks_true_s2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
